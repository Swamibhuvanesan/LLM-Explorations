# Image Captioner

This project utilizes the `transformers` library to generate captions for given images using a pre-trained model from Huggingface. The specific model used is `Salesforce/blip-image-captioning-base`.

## 📝 Description

The **Image Captioner** project is designed to generate descriptive captions for any given image. This can be particularly useful for tasks involving image recognition, accessibility features, and enhancing user experience in various applications.

## 🚀 Getting Started

### Prerequisites

Ensure you have the following dependencies installed:
- Python 3.7 or higher

### Setting Up a Virtual Environment

It is recommended to use a virtual environment to manage your dependencies. You can set up a virtual environment using the following commands:

```sh
# Create a virtual environment
python -m venv venv

# Activate the virtual environment
# On Windows
venv\Scripts\activate
# On macOS/Linux
source venv/bin/activate
